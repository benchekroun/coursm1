\documentclass{article}
\usepackage[utf8]{inputenc} % un package
\usepackage[T1]{fontenc}      % un second package
\usepackage[francais]{babel}  % un troisième package


\title{IA- Matthieu Exbrayat}
\author{Alexandre Masson}
\date{14 Janvier 2013}

\begin{document}
\maketitle
\newpage
\tableofcontents
\newpage
\section{Organisation du cours}
\paragraph{} Cours de 2h le mardi et TD 2 h le mercredi.\\\\
\section{Introduction}
\paragraph{Questions} Qu'est ce que les taches suivantes ont en commun ?\\\\
Concevoir des systèmes capables de faire des choses compliquées.\\Il y a aussi l'aspect ; apprentissage , le système est il capable d'apprendre de lui même et se débrouille tout seul.\\Exemples:\\Concevoir un programme qui vire tout seul les spam dans les mails.\\Concevoir un super navigateur qui s'occupe tout seul de faire les mise à jour logicielle.\\\\Le point commun? Posséder un certain degré d'intelligence.\\D'où grande question qu'est ce que l'intelligence ? 
\begin{itemize}
\item Selon Darwin : Ce qui permet l'individu le plus apte, parfaitement adapté a son environnement
\item Selon Edison : ce qui fonctionne et qui produit de l'argent. 
\item Selon Turing : ce qui rend difficile la distinction entre une tache réalisée par un être humain ou une machine
\end{itemize}
L'IA est une discipline qui systématise et automatise les taches .
\begin{itemize}
\item Penser comme un humain
\item Agir comme un humain
\item Penser rationnellement
\item Agir rationnellement
\end{itemize}
\paragraph{Penser comme un humain} Il faut comprendre l'esprit Humain.\\Comparaison des différentes étapes d'un programme et du raisonnement humain pour arriver au même problème.\\Science cognitive.
\paragraph{Agir comme un humain} Test de Turing, on transforme l’ordinateur peut il penser en peut il se comporter intelligemment. Le test est concluent si l'opérateur ne sais pas si la réponse a ses question est donnée par un humain ou une machine
\paragraph{Penser rationnellement : approche logique}
\newpage
\paragraph{Agir rationnellement : agir pour atteindre un objectif}Remplir une mission de la meilleure façon.\\\\Agent : unité qui fonctionne de façon autonome, perçoit son environnement , s'adapte aux changements et est capable d'atteindre un objectif.\\\\Agent Rationnel : agent qui agit pour atteindre le meilleur résultats ou du moins le meilleur résultat espéré.
\paragraph{Loebner prize} Tous les ans récompense le meilleur système du test de Turing.
\begin{itemize}
\item traitement du langage naturel : pouvoir communiquer en un langage naturel.
\item représentation de connaissances : stocker ce qu'il sait ou ce qu'il perçoit.
\item raisonnement automatique : utiliser des connaissances pour répondre aux questions.
\end{itemize}

\paragraph{les Lois de la pensée}Aristote : quels sont les processus de pensée corrects ?\\Plusieurs formes de logique : notation et règles de dérivation pour les pesées , sans relations avec une mécanisation du raisonnement.\\Ligne directe entre math et philo -> IA.\\Problèmes : tous les comportements intelligents ne sont pas le résultats d'un raisonnement logique.\\
\paragraph{Agent Rationnel} abstrait : un agent est une fonction qui met en correspondance des séquences perceptives P* et des actions A : f : P* -> A.\\\\processus où on ne sais pas tout, ou temps limité trop court pour répondre, donc réponse acceptable mais pas optimale.
\paragraph{Fondements de l'IA}Elle repose sur plusieurs domaines.\\\\Philosophie : logique et raisonnement.\\\\Mathématiques : représentations formelles et preuves, algorithmes, (in)décidabilité, probabilité.\\\\Psychologie : adaptation, perception et controle moteur, techniques expérimentales.\\\\Linguistique : représentation de connaissances grammaires.\\\\Neurosciences : substrat physique et biologique de l'activité mentale.\\\\Théorie du controle : systèmes asservis, stabilité, concept d'agent optimal.

\section{Histoire de l'IA}
\begin{itemize}
\item 1943 : modélisation de neurones.
\item 1950's : vision complète de l'IA
\item 60's : dev des réseaux de neurones.
\item 70's : développement des systèmes à base de connaissances, faire de l'aide au diagnostic.
\item fin 80's : hiver de l'IA, l'ia s’effondre
\item depuis 20 ans : IA évolue et révolutionne sa méthodologie.
\item plein de fric à se faire dans la Bourse, algorithme qui réagissent au plus vite et essaye d'analyser la bourse pour établir des règles. 
\end{itemize}

\paragraph{Prédictions et réalité} différence prédictions réalité ;,  60's œil électronique, pas encore fait mais ça avance et s'est encourageant.\\\\ Robot qui font tout, déjà dans les 70's.
\section{Qu'est ce qu'un problème pour l'IA}
Problème qui n'as pas de solution analytique connue, objectif : si l'objectif est hors du possible donner une solution acceptable en temps raisonnable.\\\\Certaines taches aisées pour l'humain sont difficiles pour la machine : tout ce qui a besoin de la sensibilité humaine.

\paragraph{Contenu du cours} 4 approches différentes de la résolution de problèmes en IA
\begin{itemize}
\item recherche de solution dans un espace d'états
\item recherche par raisonnement et en présence d'incertitude
\item résolution par planification.
\item résolution par apprentissage automatique
\end{itemize}

\section{Agents Intelligents}
\paragraph{Qu'est ce qu'un agent}
L'AGENT perçoit des choses de son ENVIRONNEMENT, à laide de SENSORS,  il accompli ensuite sa MISSION, et utilise ses ACCUATORS, pour effecteur des actions.\\\\Définition : entité capable de percevoir son environnement par des capteurs et d'agir sur son environnement à l'aide d’effecteurs (actionneurs). AUTONOMIE , PERCEPTION,ACTION,OBJECTIF, sont les maitres-mots qui définissent l'existence de l'agent.
\paragraph{spécification d'un agent} le choix d'une action à l'instant t dépend de séquences perceptives .
\paragraph{Agent rationnel}Basé sur le raisonnement.\\\\Toute option considérées , faire le meilleur choix pour maximiser les chances de succès.\\\\Mesures de performances : réussir la tâches, quantification maximale d'un objectif.
\paragraph{spécifier l'environnement}
 spécif = problème, agent ) solution
\paragraph{PEAS} exemple , conduite automatique 
\begin{itemize}
\item P (mesure de performance) : bon endroit, temps, sécurité
\item E (environnement) : rues, voitures, piétons, météo
\item A (actions) : tourner , arrêter , klaxonner, etc...
\item S (senseurs) : plein.
\end{itemize}

\paragraph{types d'environnement} 
Observable ou nono , et déterministe ou non., Observable : on a accès à tout moment à l'état complet de l'environnement. Déterministe : on connais l'instant suivant à partir de l'état courant et l'action faite par l'agent.\\\\Épisodique/séquentiel : les états futurs ne dépendent pas des actons effectuées lors de évents précédents.\\\\Statique/dynamique : un environnement ne change pas durant le temps ou l'agent réfléchit.\\\\Discret/continu : environnement discret si le nombre de séquences est fini. Simple agent ou multi-agents. les appli du monde réel sont les plus difficile à mettre en place car l'environnement n’est que partiellement observable, il est séquentiel, dynamique, continu et multi-agent.
\newpage
\paragraph{types d'agents}
\begin{itemize}
\item Agent-reflex : presque tout est codé en dur, on applique des règles en fonction de se qu'on observe de l'environnement.
\item Agent-reflex avec états : on va conserver des états qui vont servir à estimer des états en fonction de se qu'on viens de capter et ainsi que ce que l'on a sauvegardé. Mettre a jour l'état interne dépend de comment l'env change et comment nos action le font évoluer.
\item Agent avec objectif. le Système va être dans un état donné, et après on regarde toutes les solution dispo et on va choisir celle qui nous rapproche le plus de l'objectif. IL a un objectif que décrit les situations désirées. il combien ces informations avec la résultat pour choisir la bonne action. l'agent devrait être capable de considérer des longues séquences pour atteindre l'objectif : \textbf{recherche} et \textbf{planification}.
\item Agent avec la fonction d'utilité : parmi la listes des actions proposées celle qui est la plus prometteuse. On est déjà sur des solutions sophistiquées. Il n'est pas capable de s'améliorer lui même.
\item Agent d'apprentissage : il reçoit des signaux et choisis quoi faire et indique ces décisions. il va ensuite essayer de savoir si ça décision est pertinente. Il a des exemples d’actions et de suites d'actions qu'il a effectuées, il sais si ces actions sont bien choisies ou pas
\end{itemize}
IL est nécessaire d'etre capable de stocker des processus qui vont prendre des décisions. La vision PEAS est une modélisation simple. 

\section{Problèmes et algorithmes de recherche}
\subsection{Agents de résolutions de problèmes}
\paragraph{Intro aux algorithmes de recherche}
Les algorithmes de recherche constituent l'une des approches les plus puissantes pour la résolution de problème en IA.\\\\ Les algo de recherche sont un mécanisme de recherche général de résolution. On sais toujours tout ce qui peux être fait depuis cet état mais on ne peux pas savoir à l'avance si cet état en bon ou pas. On effectue à chaque action un test de solution. On sais a quoi ressemble un état qui peux être une solution, et il est aussi intéressant de savoir comment nous sommes arrivé a la solution. Plusieurs approche possible en largeur ou en profondeur. Exemple : voyage d'un bout à l'autre de la Bulgarie.\\\\Autre exemple  : jeu de taquin : puzzle-8 : on a des cases dans un ordre aléatoire, mais on veux arriver a avoir toutes les cases dans l'ordre.
\newpage
\paragraph{Définition d'un problème de recherche} 
Formalisons un ptit peu ça  : tous les états sont dans un ensemble Q : non vide, il y a parmi ceux la des états initiaux(S). On a aussi un ensemble d'état solutions(G) : définis explicitement, ou implicitement avec des règles de tests. A : un ensemble d'actions . Fonction de successeurs, et parfois une fonction de coût : cela nous permet de pouvoir estimer si une décision est bonne ou pas. Nous avons besoin de définir tous ces éléments pour définir les problèmes de recherche. Exemple :\\Aspirateur : 
problème assez simple. Solution : séquence d'opération .\\\\Il existe aussi des problèmes plus compliqué , les problèmes contingents :  effet conditionnel des actions, perception fournit des nouvelles infos de l'état courant, la solution est un arbre ou une stratégie. IL existe aussi les problèmes d'exploration : l'exécution révèle les états, besoin d'expérimenter pour trouver la solution.
\subsection{Formulation d'un problème à état unique}
Un problème est défini par 4 éléments : \\état initial : être à Arad.\\Fonction de successeur.\\test : implicite : NoDirt(x), ou explicite : "être à Zerind". Tous les problèmes qui peuvent être  décrits par : un ensemble fini d'états, un ensemble fini d'actions, un sous-ensemble d'états initiaux et solutions, une relation successeur définie sur l'ensemble des actions et qui renvoie vers l'ensemble des états et une fonction de coût qui est positive.
\subsection{Stratégies}
Elles sont évaluées sur 4 critères : Complétude : si une solution existe, le système va t il l'atteindre.\\complexité en temps : combien de nœuds on est censé explorer. Deux grandes familles, aveugles et heuristiques.
\paragraph{Stratégies Aveugles}
On utilise la recherche en profondeur limitée, pour profiter de la vitesse de calcul de la largeur, mais aussi de l'utilisation mémoire plus satisfaisante de la recherche en profondeur. Cette solution est complète, sa complexité en temps est $O(b^{d})$, sa complexité en espace est O(bd). Optimalité, si le coût pour passer d'une étape à une autre est unitaire, car toues les solution d'un même niveau ont le même coût.\\\\\textbf{Arbre de recherche bidirectionnelle} nécessite de connaître explicitement les états finaux, et des actions sont on connais la fonction inverse, on pars de la source et des solutions, et on construit en fonction de la longueur des chemins tous les nœuds accessibles, et on regarde s'il y a des matchs.\\\\Quelle solution prendre ? Si on a pas trop de problème de mémoire , le bidirectionnel est le plus efficace, si on a des contraintes de mémoire, on aura plus intérêt a prendre la recherche par profondeur itérative.
\paragraph{États répétés}
L’échec de détection d'états répétés risque de produire des arbres de recherche infinis.\\En largeur, garder une trace de tous les états déjà parcouru, si l'état d'un nouveau nœud existe déjà , alors on le supprime. 
\paragraph{Recherche heuristiques} 
Nous allons utiliser une fonction heuristique , de l'ensemble des états vers les réels comme une estimation du rapport coût bénéfice qu'il y a a étendre le chemin courant en passant par s.\\\\\textbf{Idée : }Utilisation d'une fonction d'évaluation (heuristique) pour chaque nœud, étendre avec le plus prometteur selon la fonction heuristique. On utilise souvent l'approche gloutonne pour minimiser le coût des transitions. Cette approche gloutonne est elle complète? : il existe des cas où l'on boucle., mais complet dans un espace fini sans boucle.\\\\En terme de temps , c'est de l'ordre , facteur de branchement avec en exposant la profondeur maximum, pareil en espace, car il faut garder en mémoire tous les nœuds. La performance de cette approche gloutonne, dépend de la précision de la fonction heuristique, il est possible de réduire fortement les contraintes de temps et d'espace.\\\\Une fonction heuristique est admissible (qui ne surestime jamais le coût réel si elle est supérieure a 0 , et inférieur au coût optimal réel, une fonction heuristique est toujours optimiste!\\\\L'idée va être de combiner le greedy search(glouton), réduisant le coût , mais pas toujours optimal, avec le coût uniforme, qui lui est optimal, mais pas très efficace, pour arriver a une solution admissible.\\\\Cela nous mène a l'algorithme A*, éviter de choisir le chemin qui est déjà coûteux, on ne va plus uniquement regarder vers l'avant , mais aussi vers l'arrière, pour prendre n compte le chemin qui mène a un nœud, en plus de sa capacité a nous rapprocher du but.
\newpage

\textbf{Complétude du Lemme} Oui , sauf dans le cas ou on a un facteur de branchement infini, \\\textbf{Temps} Exponentiel,\\\textbf{Espace} Exponentiel, il faut garder tous les nœuds en mémoire,\\\textbf{Optimalité} Oui , $f_{i+1}$ n’est pas étendu tant que $f_{i}$ n'est pas fini.\\A* étend tous les nœuds ayant f(n) < C*\\A* étend quelques nœuds ayant f(n) = C*\\A* n'étend aucun nœud ayant f(n) > C*
\paragraph{Qualité de fonction heuristique} Facteur de branchement effectif, soit N le nombre total d'états produits pour obtenir la solution, soit d la profondeur à laquelle la solution a été trouvée alors b* est la facteur de branchement d'un arbre fictif parfaitement équilibré tel que
\begin{center}
$ N = 1 + b^{*} + (b^{*})^{2} +...+ (b^{*})^{d}$
\end{center} 
Une bonne fonction heuristique aura une valeur de $b^{*}$ proche de 1 (la fonction heuristique idéale aurait $b^{*}= 1$)
\paragraph{Dominance} Si $h_{2}(n) >= h_{1}(n), \forall n $ (les deux étant admissibles) alors $h_{2}$ domine $h_{1}$ et constitue une meilleure fonction heuristique. \\\textbf{problème simplifié} Une heuristique admissible peut être dérivée à partir du coût exact de la solution d'une version "simplifiée" du problème \\\textbf{Point clé } Vérifier que le coût optimal du problème simplifié n'est pas plus grand que le coût du problème initial.
\paragraph{Variantes de A*} Les problèmes réels sot souvetn très complexes\\L'espace de recherche devient très grand\\Meme les méthodes de recherche heuristique deviennent inefficaces\\A* : complexité en espace exponentiel.\\IDA* = approfondissement itératif de A*\\SMA* = A* avec gestion mémoire.
\paragraph{IDA*} IDS effectue l'approfondissement par rapport à la profondeur de la recherche\\IDA* utilise comme limite la la valeur de la fonction heuristique f(n), chaque itération de IDA* est une recherche en profondeur, la profondeur limite correspond à la plus petite valeur observé au delà de la limite de l'étape précédente.\\IL est complet et optimal\\Complexité en espace de IDA* : O(bd), ok pour coût unitaire, mais qu'en est il pour des coûts réels? \\\\\textbf{Un alternative : RBFS}\\Récursive  BFS\\Approche best-first, mais\\Enregistre dans chaque nœud le f du meilleur chemin alternatif\\remonte si le cout est supérieur à un f mémorisé\\En remontant, mémorise ce cout (pour redescendre si besoin)\\+ efficace qu'IDA* mais risque de redévelopper beaucoup de nœuds\\Optimale (si h est admissible), espace O(bd) , temps ?\\PB : la faible complexité en espace est finalement gênante.
\paragraph{SMA*} Simplified Memory bounded A*\\SMA* effectue sa propre gestion de mémoire\\principe \begin{itemize}
\item si la mémoire (file d'attente) est pleine, alors faire de la place en éliminant le nœud le moins intéressant (celui avec une valeur f élevée)
\item retenir dans le nœud ancêtre la valeur du meilleur descendant oublié

\end{itemize}
\textbf{Propriétés} 
\begin{itemize}
\item espace mémoire alloué par avance
\item évite les états multipliés
\item complet si espace mémoire suffisant
\end{itemize}

\section{5 Mars 2013}
\paragraph{} Les algos de recherche locale sont adaptés aux pbs ou on cherche une solution mais on ne s'occupe pas du chemin. Ils considèrent un état courant, puisse déplacent successivement vers un état voisin par relation de voisinage. \\\\\textbf{propriété} il sont : non-complets, non-optimaux, et non-exhaustifs, MAIS, utilisent peu de mémoire, souvent en quantité constante, ils conviennent aux recherches "offline" et "online".\\ Ils trouvent souvent des solutions raisonnables dans des espaces d'états très grands, voir infini, où les autres algos ne peuvent pas s'appliquer.\\ils s'adaptent aux problèmes d'optimisation où l'on cherche le meilleur état suivant une fonction d'objectif.\\ un voisinage s'obtient en perturbant légèrement un état, on définit une distance $V(s) = \{s' |d(s,s') < \epsilon\}$.\\on considère une fonction de cout qui mesure l'écrat entre l'état et l'objectif ou simplement la valeur de l'état courant, on cherche à optimiser cette fonction.\\\\\textbf{Exemple : TSP}\\ L'état initial est un tour quelconque , puis les états voisins sont obtenus successivement en échangeant deux déplacements. des variantes de cette méthode trouvent une solution raisonnable rapidement avec des centaines de villes.\\\\\textbf{hill climbing (approche par escalade)}\\ le principe consiste à rechercher , parmis les voisins , celui qui améliore le plus al fonction de cout, on recommence jusqu'au max, souvent max local, l'algo est glouton.

\paragraph{Satisfaction de clauses booléenne} problème NP-Complet, distance de Hamming, nombre de bits différents. cout : nombre de clauses satisfaite par ce changement de bit. on pondère avec le nombre de variable, car les grandes clauses sont plus difficiles a satisfaire. l'algorithme peux osciller dans un maximum local, s'il il n'y a pas de réponse, on peut relancer l'algorithme. pour le climbing, il faut pouvoir sortir des plateaux (même valeur plusieurs fois), mais avec mouvement random, risque de boucler sur un plateau.
\paragraph{le recuit simulé}\\ idée, autoriser de redescendre vers un état moins bon avec une certaine probabilité.\\ La probabilité de descente dépend d'un paramètre appelé \textit{température} \\Au cours de la recherche, on diminue progressivement la température.\\température élevée : recherche + aléatoire -> exploration de larges zones de l'espace de recherche\\recuit simulé = simulated annealing.

\paragraph{local beam search} garder K successeurs au oieu d'un , pas le meme comportement avec k recherches en parallèles, souvent k états finissent par se retrouver dans un maximum local. Idée : choisir k successeurs aléatoirement , \textit{stochastic beam search} Analogie dans la sélection naturelle. 

\section{Les algorithmes génétiques} 
\paragraph{le principe} maintenir une population de solutions candidates appelées individus(= états).\\coder chaque individus (ses gènes).\\générer au hasard une population initial.\\exécuter le cycle suivant jusqu’à obtention d'un critère d’arrêt : Sélection -> reproduction -> mutation

\section{Jeux}
\paragraph{intro} jeu constitue première branche de l'ia, premier sujet, les échecs, dans certains jeu, les algo actuel surpassent les humains. Exemple : deep blue : projet de 1985, deux séries, 300M de calcul par secondes, profondeur de 12 demi-coups de profondeur. Théorie des jeux, plusieurs participants (ou adversaires ou agents), principe de coop ou rivalité, en IA  : 
\begin{itemize}
\item a la basse , jeux alternés, déterministe, a somme nulle (ce que l'un gagne, l'autre le perd).
\item notion de gain 
\item contrainte de temps.
\end{itemize}

\paragraph{de quoi dispose t on } état initial, fonction successeur(coup,état) -> notion de coup légal, test de terminaison(-> états terminaux), fonction d'utilité(ou de gain)(associe un score a chaque état, généralement associé au décompte des scores spécifique).\\\\
Les joueurs jouent à tour de rôle, un cou p = 2 demi-coup, le score et donné par joueur, l'un des joueurs essaie d'avoir le plus de score, et l'autre le moins.\\\\\textbf{mini-max} stratégie optimale, reposant sur un exploration complexe : idée : trouver à chaque étape, le coup assurant un gain maximum (c’est a dire limitant les possibilités de gain de l'adversaire. On donne un score à chaque noeud et à chaque voisins pour choisir le meilleur. mini-max et multijoueur, on doit tenir compte de de l’intérêt de tous les joueurs, les résultats des fonction utilité, sont des vecteurs, ou chaque élément représente un des joueurs, alors lors des comparaisons pour le choix d'une action, chaque joueurs regarde le composante du vecteur qui le concerne et choisit le plus haut. \textbf{Bilan} Exploration complète, parcours en profondeur, coût en temps $O(b^m)$, coût en espace en $O(bm)$, adapté au problème simples. Peut on éviter certaines branches?
\paragraph{Alpha-bêta} Certain sous arbres sont inintéressant pour le joueur courant :e.g : on sais qu'il existe une super opportunité pour l'adversaire. technique élagage, suppose d'avoir des certitudes sur l’intérêt d'une branche -> génération d'au moins une feuille, évaluation  de l’intérêt ?. en gros, si on trouve un sous arbre moins intéressant, alors on l'explore pas (soit max moins grand , soit min plus grand). \textbf{bilan} efficacité dépend de l’ordre des successeurs. Amélioration : table de transposition, souvent plusieurs chemin mènent a un même état , le premier passage permet de faire l'élagage. Mémorisation des états (les plus intéressants dans une table de hachage(pas besoin de recalculer les successeur d'une config déjà connue, car on connais déjà sa valeur d'utilité.
\paragraph{décision imparfaite en temps réel} Dans la plupart des jeux il n'est pas possible de déplier tous les coups possibles. il faut jouer le mieux possible ne temps raisonnable, fonction d'évaluation, test d’arrêt. Fournit une estimation de l'utilité espérée pour une position donnée, fonction heuristiques. Critère : pas trop pourrie, temps de calcul maîtrisé (meme si on explore pas tout, l’intérêt doit être calculé vite, elle doit rendre le même résultats que la fonction d'utilité pour les états terminaux. Principe: description de l'état : attributs, première approche : classification, états -> classes = indexation. info statistiques par classe( e.g  \% de victoire, de défaite, de nul), valeur espérée : somme pondérée (pondération = score associé). risque d'avoir de nombreuses catégories. \\ une approche plus réaliste  : fonction linéaire des attributs : on accorde un poids a chacun des attributs, et on fait la somme pondérée. Dans cette formule, on suppose l’indépendance des attributs.\\ Test d'arret : reprise de l'approche de alpha-bêta ne remplaçant le test d'état terminal par un test cut-off, suppose de gérer la profondeur courante de et fixer la profondeur d de cut off., autre approche : exploration itérative(ids) , meilleur solution atteinte lorsque le temps est écoulé. \textbf{Améliorations} Recherche d'états stables cut off , éloignées de possibilités d'inversements de valeurs.

\paragraph{Hasard} les possibilités de coup pour soi ou pour l'autre est non déterministes, on ajoute des noeuds intermédiaire pour 
\end{document}